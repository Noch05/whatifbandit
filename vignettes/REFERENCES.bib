@misc{bengtsson2025,
  title = {Future: {{Unified Parallel}} and {{Distributed Processing}} in {{R}} for {{Everyone}}},
  shorttitle = {Future},
  author = {Bengtsson, Henrik},
  year = {2025},
  month = jun,
  urldate = {2025-07-14},
  abstract = {The purpose of this package is to provide a lightweight and unified Future API for sequential and parallel processing of R expression via futures. The simplest way to evaluate an expression in parallel is to use 'x \%{$<$}-\% \{ expression \}' with 'plan(multisession)'. This package implements sequential, multicore, multisession, and cluster futures. With these, R expressions can be evaluated on the local machine, in parallel a set of local machines, or distributed on a mix of local and remote machines. Extensions to this package implement additional backends for processing futures via compute cluster schedulers, etc. Because of its unified API, there is no need to modify any code in order switch from sequential on the local machine to, say, distributed processing on a remote compute cluster. Another strength of this package is that global variables and functions are automatically identified and exported as needed, making it straightforward to tweak existing code to make use of futures.},
  copyright = {LGPL-2.1 {\textbar} LGPL-3 [expanded from: LGPL ({$\geq$} 2.1)]},
  keywords = {HighPerformanceComputing}
}

@misc{bengtsson2025a,
  title = {Future.Batchtools: {{A Future API}} for {{Parallel}} and {{Distributed Processing}} Using 'Batchtools'},
  shorttitle = {Future.Batchtools},
  author = {Bengtsson, Henrik},
  year = {2025},
  month = jun,
  urldate = {2025-07-14},
  abstract = {Implementation of the Future API {$<$}doi:10.32614/RJ-2021-048{$>$} on top of the 'batchtools' package. This allows you to process futures, as defined by the 'future' package, in parallel out of the box, not only on your local machine or ad-hoc cluster of machines, but also via high-performance compute ('HPC') job schedulers such as 'LSF', 'OpenLava', 'Slurm', 'SGE', and 'TORQUE' / 'PBS', e.g. 'y {$<$}- future.apply::future\_lapply(files, FUN = process)'.},
  copyright = {LGPL-2.1 {\textbar} LGPL-3 [expanded from: LGPL ({$\geq$} 2.1)]},
  keywords = {HighPerformanceComputing}
}

@article{bibaut2021,
  title = {Post-{{Contextual-Bandit Inference}}},
  author = {Bibaut, Aur{\'e}lien and Chambaz, Antoine and Dimakopoulou, Maria and Kallus, Nathan and {van der Laan}, Mark},
  year = {2021},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {28548--28559},
  issn = {1049-5258},
  abstract = {Contextual bandit algorithms are increasingly replacing non-adaptive A/B tests in e-commerce, healthcare, and policymaking because they can both improve outcomes for study participants and increase the chance of identifying good or even best policies. To support credible inference on novel interventions at the end of the study, nonetheless, we still want to construct valid confidence intervals on average treatment effects, subgroup effects, or value of new policies. The adaptive nature of the data collected by contextual bandit algorithms, however, makes this difficult: standard estimators are no longer asymptotically normally distributed and classic confidence intervals fail to provide correct coverage. While this has been addressed in non-contextual settings by using stabilized estimators, the contextual setting poses unique challenges that we tackle for the first time in this paper. We propose the Contextual Adaptive Doubly Robust (CADR) estimator, the first estimator for policy value that is asymptotically normal under contextual adaptive data collection. The main technical challenge in constructing CADR is designing adaptive and consistent conditional standard deviation estimators for stabilization. Extensive numerical experiments using 57 OpenML datasets demonstrate that confidence intervals based on CADR uniquely provide correct coverage.},
  langid = {english},
  pmcid = {PMC9249103},
  pmid = {35785105}
}

@misc{emden2020,
  title = {Contextual: {{Evaluating Contextual Multi-Armed Bandit Problems}} in {{R}}},
  shorttitle = {Contextual},
  author = {van Emden, Robin and Kaptein, Maurits},
  year = {2020},
  month = jan,
  number = {arXiv:1811.01926},
  eprint = {1811.01926},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1811.01926},
  urldate = {2025-05-16},
  abstract = {Over the past decade, contextual bandit algorithms have been gaining in popularity due to their effectiveness and flexibility in solving sequential decision problems---from online advertising and finance to clinical trial design and personalized medicine. At the same time, there are, as of yet, surprisingly few options that enable researchers and practitioners to simulate and compare the wealth of new and existing bandit algorithms in a standardized way. To help close this gap between analytical research and empirical evaluation the current paper introduces the object-oriented R package "contextual": a user-friendly and, through its object-oriented structure, easily extensible framework that facilitates parallelized comparison of contextual and context-free bandit policies through both simulation and offline analysis.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\AX39E7UE\\Emden and Kaptein - 2020 - contextual Evaluating Contextual Multi-Armed Bandit Problems in R.pdf;C\:\\Users\\noaho\\Zotero\\storage\\CAUA8IE2\\1811.html}
}

@misc{grover2018,
  title = {Best Arm Identification in Multi-Armed Bandits with Delayed Feedback},
  author = {Grover, Aditya and Markov, Todor and Attia, Peter and Jin, Norman and Perkins, Nicholas and Cheong, Bryan and Chen, Michael and Yang, Zi and Harris, Stephen and Chueh, William and Ermon, Stefano},
  year = {2018},
  month = mar,
  number = {arXiv:1803.10937},
  eprint = {1803.10937},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1803.10937},
  urldate = {2025-05-31},
  abstract = {We propose a generalization of the best arm identification problem in stochastic multi-armed bandits (MAB) to the setting where every pull of an arm is associated with delayed feedback. The delay in feedback increases the effective sample complexity of standard algorithms, but can be offset if we have access to partial feedback received before a pull is completed. We propose a general framework to model the relationship between partial and delayed feedback, and as a special case we introduce efficient algorithms for settings where the partial feedback are biased or unbiased estimators of the delayed feedback. Additionally, we propose a novel extension of the algorithms to the parallel MAB setting where an agent can control a batch of arms. Our experiments in real-world settings, involving policy search and hyperparameter optimization in computational sustainability domains for fast charging of batteries and wildlife corridor construction, demonstrate that exploiting the structure of partial feedback can lead to significant improvements over baselines in both sequential and parallel MAB.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\R7ST4NYI\\Grover et al. - 2018 - Best arm identification in multi-armed bandits with delayed feedback.pdf;C\:\\Users\\noaho\\Zotero\\storage\\U7MTSP8Y\\1803.html}
}

@article{hadad2021a,
  title = {Confidence Intervals for Policy Evaluation in Adaptive Experiments},
  author = {Hadad, Vitor and Hirshberg, David A. and Zhan, Ruohan and Wager, Stefan and Athey, Susan},
  year = {2021},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {118},
  number = {15},
  pages = {e2014602118},
  issn = {1091-6490},
  doi = {10.1073/pnas.2014602118},
  abstract = {Adaptive experimental designs can dramatically improve efficiency in randomized trials. But with adaptively collected data, common estimators based on sample means and inverse propensity-weighted means can be biased or heavy-tailed. This poses statistical challenges, in particular when the experimenter would like to test hypotheses about parameters that were not targeted by the data-collection mechanism. In this paper, we present a class of test statistics that can handle these challenges. Our approach is to adaptively reweight the terms of an augmented inverse propensity-weighting estimator to control the contribution of each term to the estimator's variance. This scheme reduces overall variance and yields an asymptotically normal test statistic. We validate the accuracy of the resulting estimates and their CIs in numerical experiments and show that our methods compare favorably to existing alternatives in terms of mean squared error, coverage, and CI size.},
  langid = {english},
  pmcid = {PMC8054003},
  pmid = {33876748},
  keywords = {adaptive experimentation,Algorithms,central limit theorem,Data Interpretation Statistical,frequentist inference,multiarmed bandits,policy evaluation,Randomized Controlled Trials as Topic},
  file = {C:\Users\noaho\Zotero\storage\7FRS78IN\Hadad et al. - 2021 - Confidence intervals for policy evaluation in adaptive experiments.pdf}
}

@article{imbens1997,
  title = {Bayesian Inference for Causal Effects in Randomized Experiments with Noncompliance},
  author = {Imbens, Guido W. and Rubin, Donald B.},
  year = {1997},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {25},
  number = {1},
  pages = {305--327},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1034276631},
  urldate = {2025-05-19},
  abstract = {For most of this century, randomization has been a cornerstone of scientific experimentation, especially when dealing with humans as experimental units. In practice, however, noncompliance is relatively common with human subjects, complicating traditional theories of inference that require adherence to the random treatment assignment. In this paper we present Bayesian inferential methods for causal estimands in the presence of noncompliance, when the binary treatment assignment is random and hence ignorable, but the binary treatment received is not ignorable. We assume that both the treatment assigned and the treatment received are observed. We describe posterior estimation using EM and data augmentation algorithms. Also, we investigate the role of two assumptions often made in econometric instrumental variables analyses, the exclusion restriction and the monotonicity assumption, without which the likelihood functions generally have substantial regions of maxima. We apply our procedures to real and artificial data, thereby demonstrating the technology and showing that our new methods can yield valid inferences that differ in practically important ways from those based on previous methods for analysis in the presence of noncompliance, including intention-to-treat analyses and analyses based on econometric instrumental variables techniques. Finally, we perform a simulation to investigate the operating characteristics of the competing procedures in a simple setting, which indicates relatively dramatic improvements in frequency operating characteristics attainable using our Bayesian procedures.},
  keywords = {62A10,62A15,62B15,62C10,62F15,62K99,62P99,compliers,Data augmentation,EM algorithm,exclusion restriction,Gibbs sampler,instrumental variables,Intention-to-treat analysis,lielihood-based inference,maximum likelihood estimation,Rubin Causal Model},
  file = {C:\Users\noaho\Zotero\storage\YDIPGKXY\Imbens and Rubin - 1997 - Bayesian inference for causal effects in randomized experiments with noncompliance.pdf}
}

@misc{kuleshov2014,
  title = {Algorithms for Multi-Armed Bandit Problems},
  author = {Kuleshov, Volodymyr and Precup, Doina},
  year = {2014},
  month = feb,
  number = {arXiv:1402.6028},
  eprint = {1402.6028},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1402.6028},
  urldate = {2025-07-14},
  abstract = {Although many algorithms for the multi-armed bandit problem are well-understood theoretically, empirical confirmation of their effectiveness is generally scarce. This paper presents a thorough empirical study of the most popular multi-armed bandit algorithms. Three important observations can be made from our results. Firstly, simple heuristics such as epsilon-greedy and Boltzmann exploration outperform theoretically sound algorithms on most settings by a significant margin. Secondly, the performance of most algorithms varies dramatically with the parameters of the bandit problem. Our study identifies for each algorithm the settings where it performs well, and the settings where it performs poorly. Thirdly, the algorithms' performance relative each to other is affected only by the number of bandit arms and the variance of the rewards. This finding may guide the design of subsequent empirical evaluations. In the second part of the paper, we turn our attention to an important area of application of bandit algorithms: clinical trials. Although the design of clinical trials has been one of the principal practical problems motivating research on multi-armed bandits, bandit algorithms have never been evaluated as potential treatment allocation strategies. Using data from a real study, we simulate the outcome that a 2001-2002 clinical trial would have had if bandit algorithms had been used to allocate patients to treatments. We find that an adaptive trial would have successfully treated at least 50\% more patients, while significantly reducing the number of adverse effects and increasing patient retention. At the end of the trial, the best treatment could have still been identified with a high level of statistical confidence. Our findings demonstrate that bandit algorithms are attractive alternatives to current adaptive treatment allocation strategies.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\4ICZPDUY\\Kuleshov and Precup - 2014 - Algorithms for multi-armed bandit problems.pdf;C\:\\Users\\noaho\\Zotero\\storage\\QM273RVS\\1402.html}
}

@misc{loecher2022,
  title = {Bandit: {{Functions}} for {{Simple}} a/{{B Split Test}} and {{Multi-Armed Bandit Analysis}}},
  shorttitle = {Bandit},
  author = {Loecher, Thomas Lotze {and} Markus},
  year = {2022},
  month = jun,
  urldate = {2025-05-16},
  abstract = {A set of functions for doing analysis of A/B split test data and web metrics in general.},
  copyright = {GPL-3}
}

@article{moore2022,
  title = {Anchor Management: A Field Experiment to Encourage Families to Meet Critical Programme Deadlines},
  shorttitle = {Anchor Management},
  author = {Moore, Ryan T. and Gan, Katherine N. and Minnich, Karissa and Yokum, David},
  year = {2022},
  month = dec,
  journal = {Journal of Public Policy},
  volume = {42},
  number = {4},
  pages = {615--636},
  issn = {0143-814X, 1469-7815},
  doi = {10.1017/S0143814X21000131},
  urldate = {2025-07-22},
  abstract = {Many families, despite need and eligibility, struggle to meet programme deadlines to retain critical benefits. When families fail to complete programme recertification on time, they lose needed support. While scholars have tested behavioural theories like chunking, implementation intention, and loss framing to promote programme uptake, less is known about how well-designed communications can promote continuity through successful recertification, especially where recertification entails a significant administrative burden. Further, scant evidence guides how best to frame recertification deadlines. In a randomised trial with government partners (n = 3,539), we find that sending a reminder letter informed by these behavioural theories increased the number of families maintaining participation by 14 per cent. Further, anchoring people to a deadline month may suffice to thread the motivational needle: overcoming procrastination without lowering self-efficacy by anchoring them to a specific day. Adopting the most effective letter in Washington, DC, would lead 766 more families to participate uninterrupted each year.},
  langid = {english},
  keywords = {administrative burden,behavioural science,deadlines,economic security,field experiment,recertification}
}

@article{offer-westort2021,
  title = {Adaptive {{Experimental Design}}: {{Prospects}} and {{Applications}} in {{Political Science}}},
  shorttitle = {Adaptive {{Experimental Design}}},
  author = {Offer-Westort, Molly and Coppock, Alexander and Green, Donald P.},
  year = {2021},
  month = oct,
  journal = {American Journal of Political Science},
  volume = {65},
  number = {4},
  pages = {826--844},
  publisher = {Wiley},
  issn = {0092-5853, 1540-5907},
  doi = {10.1111/ajps.12597},
  urldate = {2025-07-14},
  abstract = {Experimental researchers in political science frequently face the problem of inferring which of several treatment arms is most effective. They may also seek to estimate mean outcomes under that arm, construct confidence intervals, and test hypotheses. Ordinarily, multiarm trials conducted using static designs assign participants to each arm with fixed probabilities. However, a growing statistical literature suggests that adaptive experimental designs that dynamically allocate larger assignment probabilities to more promising treatments are better equipped to discover the best performing arm. Using simulations and empirical applications, we explore the conditions under which such designs hasten the discovery of superior treatments and improve the precision with which their effects are estimated. Recognizing that many scholars seek to assess performance relative to a control condition, we also develop and implement a novel adaptive algorithm that seeks to maximize the precision with which the largest treatment effect is estimated .},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {C:\Users\noaho\Zotero\storage\Z9ALALZG\Offer‐Westort et al. - 2021 - Adaptive Experimental Design Prospects and Applications in Political Science.pdf}
}

@misc{slivkins2024,
  title = {Introduction to {{Multi-Armed Bandits}}},
  author = {Slivkins, Aleksandrs},
  year = {2024},
  month = apr,
  number = {arXiv:1904.07272},
  eprint = {1904.07272},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1904.07272},
  urldate = {2025-07-14},
  abstract = {Multi-armed bandits a simple but very powerful framework for algorithms that make decisions over time under uncertainty. An enormous body of work has accumulated over the years, covered in several books and surveys. This book provides a more introductory, textbook-like treatment of the subject. Each chapter tackles a particular line of work, providing a self-contained, teachable technical introduction and a brief review of the further developments; many of the chapters conclude with exercises. The book is structured as follows. The first four chapters are on IID rewards, from the basic model to impossibility results to Bayesian priors to Lipschitz rewards. The next three chapters cover adversarial rewards, from the full-feedback version to adversarial bandits to extensions with linear rewards and combinatorially structured actions. Chapter 8 is on contextual bandits, a middle ground between IID and adversarial bandits in which the change in reward distributions is completely explained by observable contexts. The last three chapters cover connections to economics, from learning in repeated games to bandits with supply/budget constraints to exploration in the presence of incentives. The appendix provides sufficient background on concentration and KL-divergence. The chapters on "bandits with similarity information", "bandits with knapsacks" and "bandits and agents" can also be consumed as standalone surveys on the respective topics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\K6IX2MWS\\Slivkins - 2024 - Introduction to Multi-Armed Bandits.pdf;C\:\\Users\\noaho\\Zotero\\storage\\BILVT79N\\1904.html}
}

@misc{vaughan2022,
  title = {Furrr: {{Apply Mapping Functions}} in {{Parallel}} Using {{Futures}}},
  shorttitle = {Furrr},
  author = {Vaughan, Davis and Dancho, Matt and RStudio},
  year = {2022},
  month = aug,
  urldate = {2025-07-14},
  abstract = {Implementations of the family of map() functions from 'purrr' that can be resolved using any 'future'-supported backend, e.g. parallel on the local machine or distributed on a compute cluster.},
  copyright = {MIT + file LICENSE},
  keywords = {HighPerformanceComputing}
}

@misc{zhan2021,
  title = {Off-{{Policy Evaluation}} via {{Adaptive Weighting}} with {{Data}} from {{Contextual Bandits}}},
  author = {Zhan, Ruohan and Hadad, Vitor and Hirshberg, David A. and Athey, Susan},
  year = {2021},
  month = jun,
  number = {arXiv:2106.02029},
  eprint = {2106.02029},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.02029},
  urldate = {2025-05-16},
  abstract = {It has become increasingly common for data to be collected adaptively, for example using contextual bandits. Historical data of this type can be used to evaluate other treatment assignment policies to guide future innovation or experiments. However, policy evaluation is challenging if the target policy differs from the one used to collect data, and popular estimators, including doubly robust (DR) estimators, can be plagued by bias, excessive variance, or both. In particular, when the pattern of treatment assignment in the collected data looks little like the pattern generated by the policy to be evaluated, the importance weights used in DR estimators explode, leading to excessive variance. In this paper, we improve the DR estimator by adaptively weighting observations to control its variance. We show that a t-statistic based on our improved estimator is asymptotically normal under certain conditions, allowing us to form confidence intervals and test hypotheses. Using synthetic data and public benchmarks, we provide empirical evidence for our estimator's improved accuracy and inferential properties relative to existing alternatives.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\MS9S7GMI\\Zhan et al. - 2021 - Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits.pdf;C\:\\Users\\noaho\\Zotero\\storage\\UUXR2GSV\\2106.html}
}

@misc{zigler2017,
  title = {Posterior {{Predictive Treatment Assignment}} for {{Estimating Causal Effects}} with {{Limited Overlap}}},
  author = {Zigler, Corwin M. and Cefalu, Matthew},
  year = {2017},
  month = oct,
  number = {arXiv:1710.08749},
  eprint = {1710.08749},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1710.08749},
  urldate = {2025-05-19},
  abstract = {Estimating causal effects with propensity scores relies upon the availability of treated and untreated units observed at each value of the estimated propensity score. In settings with strong confounding, limited so-called "overlap" in propensity score distributions can undermine the empirical basis for estimating causal effects and yield erratic finite-sample performance of existing estimators. We propose a Bayesian procedure designed to estimate causal effects in settings where there is limited overlap in propensity score distributions. Our method relies on the posterior predictive treatment assignment (PPTA), a quantity that is derived from the propensity score but serves different role in estimation of causal effects. We use the PPTA to estimate causal effects by marginalizing over the uncertainty in whether each observation is a member of an unknown subset for which treatment assignment can be assumed unconfounded. The resulting posterior distribution depends on the empirical basis for estimating a causal effect for each observation and has commonalities with recently-proposed "overlap weights" of Li et al. (2016). We show that the PPTA approach can be construed as a stochastic version of existing ad-hoc approaches such as pruning based on the propensity score or truncation of inverse probability of treatment weights, and highlight several practical advantages including uncertainty quantification and improved finite-sample performance. We illustrate the method in an evaluation of the effectiveness of technologies for reducing harmful pollution emissions from power plants in the United States.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {C\:\\Users\\noaho\\Zotero\\storage\\ZWXH5I68\\Zigler and Cefalu - 2017 - Posterior Predictive Treatment Assignment for Estimating Causal Effects with Limited Overlap.pdf;C\:\\Users\\noaho\\Zotero\\storage\\I3TZ86H6\\1710.html}
}
