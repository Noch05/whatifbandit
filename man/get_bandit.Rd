% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_bandit.R
\name{get_bandit}
\alias{get_bandit}
\title{Calculate Multi-Arm Bandit Decision Based on Algorithm}
\usage{
get_bandit(
  past_results,
  algorithm,
  conditions,
  current_period = NULL,
  control_augment = 0
)
}
\arguments{
\item{past_results}{\code{data} object containing summary of prior periods.
Created by \code{\link[=get_past_results]{get_past_results()}}.}

\item{algorithm}{A character string specifying the MAB algorithm to use. Options are "Thompson" or "UCB1".}

\item{conditions}{A named character vector containing treatment conditions. The elements
of this vector should be the names of each treatment as seen in your data, so to create it you can simply call
\code{unique(df$cond)}. The names of each element are used to reference the contents but are not inherently important;
choose names that are meaningful and consistent. If \code{control_augment} > 0, then the control condition
of the trial in this vector must have the name "Control".}

\item{current_period}{Numeric scalar; current period of the adaptive trial simulation.}

\item{control_augment}{A numeric value in \link{0, 1}; proportion of each wave guaranteed to receive the "Control" treatment.
Default is 0.}
}
\value{
The bandit object for the given period.
}
\description{
Calculates the best treatment for a given period using either a UCB1 or Thompson Sampling Algorithm.
}
\seealso{
\itemize{
\item \code{\link[=run_mab_trial]{run_mab_trial()}}
\item \code{\link[=get_past_results]{get_past_results()}}
}
}
\keyword{internal}
